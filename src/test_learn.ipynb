{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path = /root/src/aleister/log/logging.log\n"
     ]
    }
   ],
   "source": [
    "from master import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'test004'\n",
    "\n",
    "# args=['--symbol','BTC', '--execute_mode',\"prepro\",\n",
    "#       '--model_id',model_id,'--model_name','slstm',\n",
    "#       '--config_source','ini',\n",
    "#       '--user',\"Misaka00001\", '--source','ipynb',\n",
    "#       \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "#       '-train_sd','20210101','-train_ed','20210103',\n",
    "#       '-valid_sd','20210104','-valid_ed','20210105',\n",
    "#       '-test_sd','20210106','-test_ed','20210107']\n",
    "\n",
    "# args=['--symbol','BTC', '--execute_mode',\"train\",\n",
    "#       '--model_id',model_id,'--model_name','slstm',\n",
    "#       '--config_source','ini',\n",
    "#       '--user',\"Misaka00001\", '--source','ipynb',\n",
    "#       \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "#       '-train_sd','20210101','-train_ed','20210103',\n",
    "#       '-valid_sd','20210104','-valid_ed','20210105',\n",
    "#       '-test_sd','20210106','-test_ed','20210107']\n",
    "\n",
    "# args=['--symbol','BTC', '--execute_mode',\"gtrain\",\n",
    "#       '--model_id',model_id,'--model_name','slstm',\n",
    "#       '--config_source','ini',\n",
    "#       '--user',\"Misaka00001\", '--source','ipynb',\n",
    "#       \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "#       '-train_sd','20210101','-train_ed','20210103',\n",
    "#       '-valid_sd','20210104','-valid_ed','20210105',\n",
    "#       '-test_sd','20210106','-test_ed','20210107']\n",
    "\n",
    "# args=['--symbol','BTC', '--execute_mode',\"deploy_model\",\n",
    "#       '--model_id',model_id,'--model_name','slstm',\n",
    "#       '--config_source','ini',\n",
    "#       '--user',\"Misaka00001\", '--source','ipynb',\n",
    "#       \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "#       '-train_sd','20210101','-train_ed','20210103',\n",
    "#       '-valid_sd','20210104','-valid_ed','20210105',\n",
    "#       '-test_sd','20210106','-test_ed','20210107']\n",
    "\n",
    "\n",
    "args=['--symbol','BTC', '--execute_mode',\"rpredict\",\n",
    "      '--model_id',model_id,'--model_name','slstm',\n",
    "      '--config_source','ini',\n",
    "      '--user',\"Misaka00001\", '--source','ipynb',\n",
    "      \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "      '-train_sd','20210101','-train_ed','20210103',\n",
    "      '-valid_sd','20210104','-valid_ed','20210105',\n",
    "      '-test_sd','20210106','-test_ed','20210107']\n",
    "\n",
    "# args=['--symbol','BTC', '--execute_mode',\"train\",\n",
    "#       '--model_id','test002','--model_name','cgm',\n",
    "#       '--config_source','ini',\n",
    "#       '--user',\"Misaka00001\", '--source','ipynb',\n",
    "#       \"--general_config_mode\", \"DOCKER\",\"--private_api_mode\",\"DEFAULT\",\n",
    "#       '-train_sd','20210101','-train_ed','20210103',\n",
    "#       '-valid_sd','20210104','-valid_ed','20210105',\n",
    "#       '-test_sd','20210106','-test_ed','20210107']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path = /root/src/aleister/log/logging.log\n",
      "Log path = /root/src/aleister/log/logging.log\n"
     ]
    }
   ],
   "source": [
    "parser = make_parser()\n",
    "arg_dict = vars(parser.parse_args(args))\n",
    "\n",
    "# meta\n",
    "_id = arg_dict[\"model_id\"]\n",
    "general_config_mode = arg_dict[\"general_config_mode\"].upper()\n",
    "private_api_mode = arg_dict[\"private_api_mode\"].upper()\n",
    "sym = arg_dict[\"symbol\"]\n",
    "\n",
    "model_name = arg_dict[\"model_name\"].upper()\n",
    "\n",
    "om = OperateMaster()\n",
    "om.load_meta(_id, model_name, sym, general_config_mode, private_api_mode)\n",
    "om.init_prepro()\n",
    "\n",
    "# mlflow\n",
    "mlflow_tags = {\n",
    "    MLFLOW_USER: arg_dict[\"user\"],\n",
    "    MLFLOW_SOURCE_NAME: arg_dict[\"source\"],\n",
    "    MLFLOW_RUN_NAME: f\"TRAIN_{dt.now().strftime('%y%m%d%H%M%s')}\"\n",
    "}\n",
    "mlflow_client_kwargs = {\n",
    "    \"tracking_uri\": os.environ['MLFLOW_TRACKING_URI']\n",
    "}\n",
    "om.set_mlflow_settings(mlflow_client_kwargs, mlflow_tags)\n",
    "\n",
    "# load conofigs into each module\n",
    "om.init_learning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path = /root/src/aleister/log/logging.log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if arg_dict[\"execute_mode\"] == \"prepro\":\n",
    "    pass\n",
    "    om.init_dataGen()\n",
    "    # period\n",
    "    train_start = arg_dict[\"train_start_date\"] if \"train_start_date\" in arg_dict.keys() else None\n",
    "    train_end = arg_dict[\"train_end_date\"] if \"train_end_date\" in arg_dict.keys() else None\n",
    "    valid_start = arg_dict[\"valid_start_date\"] if \"valid_start_date\" in arg_dict.keys() else None\n",
    "    valid_end = arg_dict[\"valid_end_date\"] if \"valid_end_date\" in arg_dict.keys() else None\n",
    "    test_start = arg_dict[\"test_start_date\"] if \"test_start_date\" in arg_dict.keys() else None\n",
    "    test_end = arg_dict[\"test_end_date\"] if \"test_end_date\" in arg_dict.keys() else None\n",
    "    # om.preprocessing(sym, train_start, train_end, valid_start, valid_end, test_start, test_end)\n",
    "else:\n",
    "    if arg_dict[\"execute_mode\"] == \"train\":\n",
    "        om.init_learning()\n",
    "        # om.train()\n",
    "    elif arg_dict[\"execute_mode\"] == \"gtrain\":\n",
    "        om.init_learning()\n",
    "        # om.gtrain()\n",
    "    elif arg_dict[\"execute_mode\"] == \"deploy_model\":\n",
    "        om.deploy_best_model()\n",
    "    elif arg_dict[\"execute_mode\"] == \"rpredict\":\n",
    "        om.init_dataGen()\n",
    "        # om.realtime_predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = om.le\n",
    "fp = om.fp\n",
    "dg = om.dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.preprocessing(sym, train_start, train_end, valid_start, valid_end, test_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp._logger.info(f\"{train_start}, {train_end}, {valid_start}, {valid_end}, {test_start}, {test_end}\")\n",
    "fetch_start = min([_date for _date in [train_start, train_end, valid_start, valid_end, test_start, test_end] if\n",
    "                   _date is not None])\n",
    "fetch_end = max([_date for _date in [train_start, train_end, valid_start, valid_end, test_start, test_end] if\n",
    "                 _date is not None])\n",
    "# dg.get_hist_data(ch=\"trade\", sym=\"BTC\", sd=\"20220101\", ed=\"20220107\")\n",
    "\n",
    "#TODO: outside\n",
    "fetch_start=train_start\n",
    "fetch_end=test_end\n",
    "output_data_structure =fp.model_config.get(\"OUTPUT_DATA_STRUCTURE\")\n",
    "input_data_structure = fp.model_config.get(\"INPUT_DATA_STRUCTURE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flatten_v1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_open</th>\n",
       "      <th>rel_high</th>\n",
       "      <th>rel_low</th>\n",
       "      <th>rel_close</th>\n",
       "      <th>rel_size</th>\n",
       "      <th>buy_size_ratio</th>\n",
       "      <th>sell_size_ratio</th>\n",
       "      <th>movingBinary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 06:00:00</th>\n",
       "      <td>-0.135220</td>\n",
       "      <td>-0.135359</td>\n",
       "      <td>-0.135220</td>\n",
       "      <td>-0.135359</td>\n",
       "      <td>-0.391074</td>\n",
       "      <td>1.445578e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 06:01:00</th>\n",
       "      <td>-0.134641</td>\n",
       "      <td>-0.135363</td>\n",
       "      <td>-0.134641</td>\n",
       "      <td>-0.135363</td>\n",
       "      <td>-2.098644</td>\n",
       "      <td>2.834467e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 06:02:00</th>\n",
       "      <td>-0.136095</td>\n",
       "      <td>-0.136817</td>\n",
       "      <td>-0.137561</td>\n",
       "      <td>-0.138283</td>\n",
       "      <td>0.233795</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.332341e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 06:03:00</th>\n",
       "      <td>-0.137557</td>\n",
       "      <td>-0.138275</td>\n",
       "      <td>-0.137558</td>\n",
       "      <td>-0.138275</td>\n",
       "      <td>-0.074774</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.620288e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 06:04:00</th>\n",
       "      <td>-0.137553</td>\n",
       "      <td>-0.138269</td>\n",
       "      <td>-0.137553</td>\n",
       "      <td>-0.138269</td>\n",
       "      <td>-2.285730</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.612103e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08 05:25:00</th>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.006820</td>\n",
       "      <td>-0.006791</td>\n",
       "      <td>-0.007083</td>\n",
       "      <td>-0.195825</td>\n",
       "      <td>5.668934e-07</td>\n",
       "      <td>1.486855e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08 05:26:00</th>\n",
       "      <td>-0.006106</td>\n",
       "      <td>-0.006828</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.922552</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.720238e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08 05:27:00</th>\n",
       "      <td>-0.005713</td>\n",
       "      <td>-0.005532</td>\n",
       "      <td>-0.005713</td>\n",
       "      <td>-0.005532</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>4.258787e-06</td>\n",
       "      <td>2.480159e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08 05:28:00</th>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>-0.797614</td>\n",
       "      <td>5.668934e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08 05:29:00</th>\n",
       "      <td>-0.006791</td>\n",
       "      <td>-0.007512</td>\n",
       "      <td>-0.007491</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>0.018793</td>\n",
       "      <td>2.735261e-07</td>\n",
       "      <td>3.010913e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10050 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rel_open  rel_high   rel_low  rel_close  rel_size  \\\n",
       "datetime                                                                 \n",
       "2021-01-01 06:00:00 -0.135220 -0.135359 -0.135220  -0.135359 -0.391074   \n",
       "2021-01-01 06:01:00 -0.134641 -0.135363 -0.134641  -0.135363 -2.098644   \n",
       "2021-01-01 06:02:00 -0.136095 -0.136817 -0.137561  -0.138283  0.233795   \n",
       "2021-01-01 06:03:00 -0.137557 -0.138275 -0.137558  -0.138275 -0.074774   \n",
       "2021-01-01 06:04:00 -0.137553 -0.138269 -0.137553  -0.138269 -2.285730   \n",
       "...                       ...       ...       ...        ...       ...   \n",
       "2021-01-08 05:25:00 -0.006339 -0.006820 -0.006791  -0.007083 -0.195825   \n",
       "2021-01-08 05:26:00 -0.006106 -0.006828 -0.006719  -0.007441 -0.922552   \n",
       "2021-01-08 05:27:00 -0.005713 -0.005532 -0.005713  -0.005532  0.081052   \n",
       "2021-01-08 05:28:00 -0.005498 -0.006125 -0.005498  -0.006125 -0.797614   \n",
       "2021-01-08 05:29:00 -0.006791 -0.007512 -0.007491  -0.008213  0.018793   \n",
       "\n",
       "                     buy_size_ratio  sell_size_ratio  movingBinary  \n",
       "datetime                                                            \n",
       "2021-01-01 06:00:00    1.445578e-06     0.000000e+00           1.0  \n",
       "2021-01-01 06:01:00    2.834467e-08     0.000000e+00           1.0  \n",
       "2021-01-01 06:02:00    0.000000e+00     5.332341e-06           1.0  \n",
       "2021-01-01 06:03:00    0.000000e+00     2.620288e-06           1.0  \n",
       "2021-01-01 06:04:00    0.000000e+00     1.612103e-08           1.0  \n",
       "...                             ...              ...           ...  \n",
       "2021-01-08 05:25:00    5.668934e-07     1.486855e-06           1.0  \n",
       "2021-01-08 05:26:00    0.000000e+00     3.720238e-07           1.0  \n",
       "2021-01-08 05:27:00    4.258787e-06     2.480159e-08           1.0  \n",
       "2021-01-08 05:28:00    5.668934e-07     0.000000e+00           1.0  \n",
       "2021-01-08 05:29:00    2.735261e-07     3.010913e-06           1.0  \n",
       "\n",
       "[10050 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tree['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=84, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48732), raddr=('127.0.0.1', 51661)>\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=85, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51661), raddr=('127.0.0.1', 48732)>\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=86, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.30.0.34', 43344)>\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=90, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.30.0.34', 43348)>\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=89, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 52003), raddr=('127.0.0.1', 34548)>\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py:1069: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=88, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34548), raddr=('127.0.0.1', 52003)>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_tree =dg.get_Xy(mode='train',input_data_structure=input_data_structure,output_data_structure=output_data_structure,sym=sym, sd=fetch_start, ed=fetch_end)\n",
    "fp._logger.info(\"[DONE] Get prepro raw datas. {0}~{1}\".format(fetch_start, fetch_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train/test/val ineach leaf\n",
    "term_splited_data_tree = fp.split_child_by_period(data_tree,train_start, train_end, valid_start, valid_end, test_start, test_end)\n",
    "fp._logger.info(\"[DONE] Split by term.\")\n",
    "\n",
    "# Make each period tree\n",
    "train_datas = fp.select_child_by_period(term_splited_data_tree, 'train')\n",
    "test_datas = fp.select_child_by_period(term_splited_data_tree, 'test')\n",
    "val_datas = fp.select_child_by_period(term_splited_data_tree, 'valid')\n",
    "fp._logger.info(\"[DONE] picked by term.\")\n",
    "\n",
    "# to ndarray objects\n",
    "train_datas = fp.get_input_structures(input_data_structure)(train_datas)\n",
    "test_datas = fp.get_input_structures(input_data_structure)(test_datas, scalers=train_datas['scaler'])\n",
    "val_datas = fp.get_input_structures(input_data_structure)(val_datas, scalers=train_datas['scaler'])\n",
    "fp._logger.info(\"[DONE] To numpy and numpy \")\n",
    "\n",
    "#  Note: If other data except  for X is using. Fix X_train\": X_trains, \"X_val\":X_vals, \"X_test\": X_tests\n",
    "fp.save_numpy_datas(**{\n",
    "    \"X_train\": train_datas['data']['X'], \"X_val\": test_datas['data']['X'], \"X_test\": val_datas['data']['X'],\n",
    "    \"y_train\": train_datas['data']['y'], \"y_val\": test_datas['data']['y'], \"y_test\": val_datas['data']['y'],\n",
    "    \"X_scaler\": train_datas['scaler'],\"note\":{'input_dim':train_datas['input_dim']}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path = /root/src/aleister/log/logging.log\n"
     ]
    }
   ],
   "source": [
    "scalers = fp.load_numpy_datas([\"X_scaler\"])\n",
    "scaler_list = []\n",
    "for scaler in scalers:\n",
    "    scaler_list.append(scaler[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MinMaxScaler()]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datas = fp.get_input_structures(input_data_structure)(test_datas, scalers=train_datas['scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MinMaxScaler()]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datas['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datasetparams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_156/1478391790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobj_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X_val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"note\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_numpy_datas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vals\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnote\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/master.py\u001b[0m in \u001b[0;36mtrain_worker\u001b[0;34m(self, X_trains, X_vals, y_train, y_val, note)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# validation if data exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_out_of_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/master.py\u001b[0m in \u001b[0;36mtest_out_of_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mdataset_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0m_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datasetparams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         _, _, test_loader, test_loader_one = self.fp.get_dataloader(self.le.hparams[\"dataset\"], X_trains=None,\n\u001b[1;32m    239\u001b[0m                                                                     \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datasetparams'"
     ]
    }
   ],
   "source": [
    "obj_keys = [\"X_train\", \"X_val\", \"y_train\", \"y_val\", \"note\"]\n",
    "X_trains, X_vals, y_trains, y_vals, note = fp.load_numpy_datas(obj_keys)\n",
    "om.train_worker(X_trains, X_vals, y_trains, y_vals,  note )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.35220309e-01, -1.35358831e-01, -1.35220309e-01, -1.35358831e-01,\n",
       "       -3.91073550e-01,  1.44557823e-06,  0.00000000e+00,  1.00000000e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99979973e-01, 5.17890703e-06, 1.49594198e-05],\n",
       "       [9.99979854e-01, 5.17760282e-06, 1.49675225e-05],\n",
       "       [9.99979854e-01, 5.16807131e-06, 1.50279675e-05],\n",
       "       ...,\n",
       "       [1.07656269e-05, 3.91482763e-06, 9.99985337e-01],\n",
       "       [1.08758677e-05, 3.94127801e-06, 9.99985218e-01],\n",
       "       [9.99778450e-01, 1.91520576e-05, 2.02424315e-04]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:188: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:188: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_228/2492342056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/master.py\u001b[0m in \u001b[0;36mgtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mlflow_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLFLOW_RUN_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{original_run_name}_{i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mlflow_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlflow_client_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlflow_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_out_of_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/master.py\u001b[0m in \u001b[0;36mtrain_worker\u001b[0;34m(self, X_trains, X_vals, y_train, y_val, note)\u001b[0m\n\u001b[1;32m    170\u001b[0m         self.le.train(train_loader, val_loader,\n\u001b[1;32m    171\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                       n_features=1)\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/learning_executor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, batch_size, n_epochs, n_features)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m#  stacked numpy data  to nu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0mtruths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "om.gtrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train worker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_trains, X_vals, y_train, y_val, note = X_trains, X_vals, y_trains, y_vals, note\n",
    "# train set up\n",
    "model_params = {_k: le.hparams[_k] for _k in le.hparams[\"structure_params\"]}\n",
    "model_params['input_dim'] = note['input_dim']\n",
    "\n",
    "le.get_model_instance(le.model_name, model_params)\n",
    "\n",
    "fp.get_dataset_fn(le.hparams[\"dataset\"])\n",
    "dataset_params = {_k: le.hparams[_k] for _k in le.hparams[\"dataset_params\"]}\n",
    "train_loader, val_loader, _, _ = fp.get_dataloader(le.hparams[\"dataset\"], X_trains, y_train, X_vals,\n",
    "                                                        y_val, None, None, **dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8c83641bbc8948f88acc2793f9e22e1a'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossfn_params = {}\n",
    "le.get_loss_fn(le.hparams[\"optimizer\"], {})\n",
    "\n",
    "optim_params = {\n",
    "    'params': le.model.parameters(),\n",
    "    'weight_decay': le.hparams[\"weight_decay\"],\n",
    "    'lr': le.hparams[\"lr\"]\n",
    "}\n",
    "\n",
    "le.get_optimizer(le.hparams[\"loss_fn\"], optim_params)\n",
    "\n",
    "# train\n",
    "le.train(train_loader, val_loader,\n",
    "              batch_size=le.hparams[\"batch_size\"], n_epochs=le.hparams[\"n_epoch\"],\n",
    "              n_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "n_epochs=10\n",
    "n_features=1\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'node_feature' and 'adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125/3632725660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batchs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batchs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batchs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batchs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/learning_executor.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, xs, ys)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'node_feature' and 'adj'"
     ]
    }
   ],
   "source": [
    "le._logger.info(\"[Start] Training. ID={0}\".format(le.id))\n",
    "# _ = le.get_model_save_path()  #todo : designate path\n",
    "\n",
    "# setup\n",
    "le.prediction = {}\n",
    "le.predictions_out = {}\n",
    "le.truths = {}\n",
    "le.truths_out = {}\n",
    "le.out_class = eval(le.model_config.get(\"OUT_CLASS\"))\n",
    "\n",
    "# mlflow\n",
    "dict_config = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"optimizer\": le.optimizer_name,\n",
    "    \"loss_fn\": le.loss_fn_name\n",
    "}\n",
    "\n",
    "le.mlwriter.create_experiment(le.id, le.mlflow_tags)\n",
    "le.mlwriter.log_params_from_omegaconf_dict(dict_config)\n",
    "\n",
    "# start\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    batch_losses = []\n",
    "    le.train_loader = train_loader\n",
    "    for x_batchs, y_batchs in train_loader:\n",
    "        le.optimizer.zero_grad()\n",
    "        loss = le.train_step(x_batchs, y_batchs)\n",
    "        batch_losses.append(loss)\n",
    "    training_loss = np.mean(batch_losses)\n",
    "    le.train_losses.append(training_loss)\n",
    "    le.mlwriter.log_metric('train_loss', training_loss, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_val_losses = []\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        for x_vals, y_val in val_loader:\n",
    "            prediction, truth, val_loss = le.eval_step(x_vals, y_val)\n",
    "            predictions.append(prediction)\n",
    "            truths.append(truth)\n",
    "            batch_val_losses.append(val_loss)\n",
    "\n",
    "        validation_loss = np.mean(batch_val_losses)\n",
    "        le.val_losses.append(validation_loss)\n",
    "        \n",
    "        predictions = np.concatenate(predictions)\n",
    "        truths = np.concatenate(truths)\n",
    "\n",
    "        # record\n",
    "        le.prediction[\"val\"], le.truths[\"val\"] = predictions, truths\n",
    "        predictions_out, truths_out = le.convert_model_value(predictions), le.convert_model_value(truths)\n",
    "        le.predictions_out[\"val\"], le.truths_out[\"val\"] = predictions_out, truths_out\n",
    "        acc = accuracy_score(truths_out, predictions_out)\n",
    "\n",
    "        le.mlwriter.log_metric('valid_acc', acc, epoch)\n",
    "        le.mlwriter.log_metric('valid_loss', validation_loss, epoch)\n",
    "        # print(le.prediction[\"val\"])\n",
    "        # print(le.predictions_out[\"val\"])\n",
    "\n",
    "    if (epoch <= 10) | (epoch % 50 == 0):\n",
    "        le._logger.info(\n",
    "            f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "# record last \n",
    "le.save_numpy_obj(predictions, \"val_preds.csv\")\n",
    "le.save_numpy_obj(truths, \"val_truth.csv\")\n",
    "le.save_numpy_obj(predictions_out, \"val_preds_out.csv\", type='int')\n",
    "le.save_numpy_obj(truths_out, \"val_truth_out.csv\", type='int')\n",
    "\n",
    "# le.save_model()\n",
    "le.save_mlflow_model()\n",
    "le._logger.info(\"[DONE] Training. ID={0}\".format(le.id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.deploy_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type({\"d\":\"dd\"})==dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = om.load_prod_model()\n",
    "om.le.load_mlflow_model(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.dg.init_mqclient(\"realtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/json/decoder.py:353: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=88, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33834), raddr=('127.0.0.1', 36091)>\n",
      "\n",
      "/usr/lib/python3.7/json/decoder.py:353: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=89, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36091), raddr=('127.0.0.1', 33834)>\n",
      "\n",
      "/usr/lib/python3.7/json/decoder.py:353: ResourceWarning:\n",
      "\n",
      "unclosed <socket.socket fd=90, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.30.0.34', 36426)>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "realtime_datas, note = om.realtime_preprocessing()\n",
    "\n",
    "# train set up\n",
    "model_params = {_k: om.le.hparams[_k] for _k in om.le.hparams[\"structure_params\"]}\n",
    "model_params['input_dim'] = note['input_dim']\n",
    "\n",
    "om.le.get_model_instance(om.le.model_name, model_params)\n",
    "\n",
    "om.fp.get_dataset_fn(om.le.hparams[\"dataset\"])\n",
    "dataset_params = {_k: om.le.hparams[_k] for _k in om.le.hparams[\"dataset_params\"]}\n",
    "_, _, _, test_loader_one = om.fp.get_dataloader(\n",
    "    om.le.hparams[\"dataset\"], None, None, None, None,\n",
    "    realtime_datas[\"data\"][\"X\"], realtime_datas[\"data\"][\"y\"], **dataset_params)\n",
    "\n",
    "prediction = om.le.predict(test_loader_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3415096 , 0.30594435, 0.35254607],\n",
       "       [0.34151688, 0.30586404, 0.35261902],\n",
       "       [0.34152302, 0.3057909 , 0.35268608],\n",
       "       [0.34153852, 0.30565593, 0.3528056 ],\n",
       "       [0.3415452 , 0.30555186, 0.35290298],\n",
       "       [0.34153417, 0.3053938 , 0.353072  ],\n",
       "       [0.34127048, 0.3050306 , 0.35369885],\n",
       "       [0.34033054, 0.3049156 , 0.3547539 ],\n",
       "       [0.337725  , 0.3060506 , 0.35622436],\n",
       "       [0.32880434, 0.3147323 , 0.3564633 ],\n",
       "       [0.33037305, 0.31286868, 0.35675827],\n",
       "       [0.32587644, 0.3180891 , 0.35603452],\n",
       "       [0.328398  , 0.31463355, 0.35696852],\n",
       "       [0.33168358, 0.31134278, 0.35697368],\n",
       "       [0.32661828, 0.3174176 , 0.35596406],\n",
       "       [0.3243381 , 0.3194604 , 0.35620144],\n",
       "       [0.3264847 , 0.3164663 , 0.35704902],\n",
       "       [0.32422766, 0.31926897, 0.35650343],\n",
       "       [0.32788235, 0.3147693 , 0.35734838],\n",
       "       [0.32715115, 0.31599855, 0.35685027],\n",
       "       [0.32450613, 0.31907368, 0.3564202 ],\n",
       "       [0.32345596, 0.31998175, 0.35656226],\n",
       "       [0.3319635 , 0.31040585, 0.35763064],\n",
       "       [0.33369064, 0.3097636 , 0.35654572],\n",
       "       [0.3379804 , 0.30620638, 0.35581326],\n",
       "       [0.3404891 , 0.30484763, 0.3546633 ],\n",
       "       [0.33675832, 0.30893096, 0.35431075],\n",
       "       [0.335459  , 0.30982327, 0.3547177 ],\n",
       "       [0.32822177, 0.31715763, 0.35462058],\n",
       "       [0.3345724 , 0.30950657, 0.355921  ],\n",
       "       [0.33400732, 0.31054065, 0.35545206],\n",
       "       [0.3303761 , 0.31418097, 0.35544285],\n",
       "       [0.32879335, 0.31524262, 0.35596406],\n",
       "       [0.3252514 , 0.31882817, 0.3559205 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.init_realpred_mq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.mq_provider.connect_mq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "om.mq_provider.publish_mq(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: mode conider\n",
    "uri = om.load_prod_model()\n",
    "om.le.load_mlflow_model(uri)\n",
    "\n",
    "realtime_datas, note = om.realtime_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# train set up\n",
    "model_params = {_k: om.le.hparams[_k] for _k in om.le.hparams[\"structure_params\"]}\n",
    "model_params['input_dim'] = note['input_dim']\n",
    "\n",
    "om.le.get_model_instance(om.le.model_name, model_params)\n",
    "\n",
    "om.fp.get_dataset_fn(om.le.hparams[\"dataset\"])\n",
    "dataset_params = {_k: om.le.hparams[_k] for _k in om.le.hparams[\"dataset_params\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " realtime_datas[\"data\"][\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "_, _, test_loader, test_loader_one = om.fp.get_dataloader(\n",
    "    om.le.hparams[\"dataset\"], None, None, None,None, \n",
    "    realtime_datas[\"data\"][\"X\"], realtime_datas[\"data\"][\"y\"], **dataset_params)\n",
    "\n",
    "prediction = om.le.predict(test_loader_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3245815 , 0.39931172, 0.27610686],\n",
       "       [0.32454658, 0.39937896, 0.2760745 ],\n",
       "       [0.32437223, 0.39966905, 0.27595875],\n",
       "       [0.3242796 , 0.39981595, 0.27590445],\n",
       "       [0.3244523 , 0.39959255, 0.2759551 ],\n",
       "       [0.3243367 , 0.39968795, 0.27597538],\n",
       "       [0.32373467, 0.39987832, 0.276387  ],\n",
       "       [0.32428795, 0.3999641 , 0.27574793],\n",
       "       [0.32314497, 0.3986499 , 0.2782052 ],\n",
       "       [0.31712675, 0.38409546, 0.2987778 ],\n",
       "       [0.31790307, 0.3901374 , 0.29195955],\n",
       "       [0.319827  , 0.39568365, 0.28448936],\n",
       "       [0.31931797, 0.39416865, 0.28651342],\n",
       "       [0.3206365 , 0.3969702 , 0.28239328],\n",
       "       [0.32299575, 0.40116313, 0.27584112],\n",
       "       [0.3189801 , 0.38995737, 0.29106253],\n",
       "       [0.32102448, 0.3962355 , 0.28274003],\n",
       "       [0.31982166, 0.3934258 , 0.28675255],\n",
       "       [0.32250905, 0.39965972, 0.27783126],\n",
       "       [0.3213373 , 0.3956371 , 0.28302556],\n",
       "       [0.3206634 , 0.39435068, 0.28498593]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "data_loader=test_loader\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    truths = []\n",
    "    le.test_loader = data_loader\n",
    "    for x_tests, y_test in data_loader:\n",
    "        prediction, truth, val_loss = le.eval_step(x_tests, y_test)\n",
    "        predictions.append(prediction)\n",
    "        truths.append(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( test_loader_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for _key in json_rst.keys():\n",
    "    try:\n",
    "        df = pd.DataFrame(json_rst[_key])\n",
    "        print(1)\n",
    "        df[\"datetime\"] = df[\"time\"].apply(lambda x: dl.strYMDHMSF_to_dt(x))\n",
    "        del df[\"time\"]\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "        dfs[_key] = df\n",
    "        dg._logger.info(f\"[DONE] Load data. Key={_key}\")\n",
    "    except Exception as e:\n",
    "        dg._logger.warning(f\"[Failure] Cannot load data. Key={_key}:{e}\",exc_info=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orderbook':                         symbol      bids0  bids0_size      bids1  bids1_size  \\\n",
       " datetime                                                                       \n",
       " 2022-04-01 18:20:13.846    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:20:14.142    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:20:14.856    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:20:15.366    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:20:15.872    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " ...                        ...        ...         ...        ...         ...   \n",
       " 2022-04-01 18:20:59.421    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:20:59.912    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:21:00.418    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:21:00.924    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " 2022-04-01 18:21:01.430    BTC  5524214.0      0.0002  5524200.0       0.001   \n",
       " \n",
       "                              bids2  bids2_size      bids3  bids3_size  \\\n",
       " datetime                                                                \n",
       " 2022-04-01 18:20:13.846  5523000.0       0.009  5520000.0      0.0096   \n",
       " 2022-04-01 18:20:14.142  5523000.0       0.009  5520472.0      0.0200   \n",
       " 2022-04-01 18:20:14.856  5523000.0       0.009  5520472.0      0.0200   \n",
       " 2022-04-01 18:20:15.366  5523000.0       0.009  5520472.0      0.0200   \n",
       " 2022-04-01 18:20:15.872  5523000.0       0.009  5521500.0      2.5000   \n",
       " ...                            ...         ...        ...         ...   \n",
       " 2022-04-01 18:20:59.421  5523000.0       0.009  5520000.0      0.0096   \n",
       " 2022-04-01 18:20:59.912  5523000.0       0.009  5520000.0      0.0096   \n",
       " 2022-04-01 18:21:00.418  5523000.0       0.009  5520000.0      0.0096   \n",
       " 2022-04-01 18:21:00.924  5523000.0       0.009  5520000.0      0.0096   \n",
       " 2022-04-01 18:21:01.430  5523000.0       0.009  5520000.0      0.0096   \n",
       " \n",
       "                              bids4  ...      asks0  asks0_size      asks1  \\\n",
       " datetime                            ...                                     \n",
       " 2022-04-01 18:20:13.846  5519600.0  ...  5524215.0        0.07  5524220.0   \n",
       " 2022-04-01 18:20:14.142  5520000.0  ...  5524215.0        0.07  5524220.0   \n",
       " 2022-04-01 18:20:14.856  5520250.0  ...  5524215.0        0.07  5524240.0   \n",
       " 2022-04-01 18:20:15.366  5520450.0  ...  5524215.0        0.02  5524240.0   \n",
       " 2022-04-01 18:20:15.872  5520480.0  ...  5524215.0        0.02  5524240.0   \n",
       " ...                            ...  ...        ...         ...        ...   \n",
       " 2022-04-01 18:20:59.421  5519700.0  ...  5524215.0        0.02  5524240.0   \n",
       " 2022-04-01 18:20:59.912  5519900.0  ...  5524215.0        0.02  5524240.0   \n",
       " 2022-04-01 18:21:00.418  5519900.0  ...  5524215.0        0.02  5524240.0   \n",
       " 2022-04-01 18:21:00.924  5519800.0  ...  5524215.0        0.02  5524240.0   \n",
       " 2022-04-01 18:21:01.430  5519800.0  ...  5524215.0        0.02  5524240.0   \n",
       " \n",
       "                          asks1_size      asks2  asks2_size      asks3  \\\n",
       " datetime                                                                \n",
       " 2022-04-01 18:20:13.846      0.0500  5524240.0      0.0125  5524343.0   \n",
       " 2022-04-01 18:20:14.142      0.0500  5524240.0      0.0125  5524343.0   \n",
       " 2022-04-01 18:20:14.856      0.0125  5524330.0      0.0500  5524343.0   \n",
       " 2022-04-01 18:20:15.366      0.0125  5524343.0      0.0100  5524405.0   \n",
       " 2022-04-01 18:20:15.872      0.0125  5524343.0      0.0100  5524405.0   \n",
       " ...                             ...        ...         ...        ...   \n",
       " 2022-04-01 18:20:59.421      0.0125  5524343.0      0.0100  5524400.0   \n",
       " 2022-04-01 18:20:59.912      0.0125  5524250.0      2.0000  5524300.0   \n",
       " 2022-04-01 18:21:00.418      0.0125  5524250.0      2.0000  5524300.0   \n",
       " 2022-04-01 18:21:00.924      0.0125  5524343.0      0.0100  5524400.0   \n",
       " 2022-04-01 18:21:01.430      0.0125  5524250.0      2.5000  5524343.0   \n",
       " \n",
       "                          asks3_size      asks4  asks4_size  \n",
       " datetime                                                    \n",
       " 2022-04-01 18:20:13.846        0.01  5526200.0      1.6003  \n",
       " 2022-04-01 18:20:14.142        0.01  5526250.0      0.1659  \n",
       " 2022-04-01 18:20:14.856        0.01  5526300.0      2.5000  \n",
       " 2022-04-01 18:20:15.366        0.10  5526400.0      2.5000  \n",
       " 2022-04-01 18:20:15.872        0.10  5526400.0      2.5000  \n",
       " ...                             ...        ...         ...  \n",
       " 2022-04-01 18:20:59.421        0.10  5524500.0      2.5000  \n",
       " 2022-04-01 18:20:59.912        2.00  5524343.0      0.0100  \n",
       " 2022-04-01 18:21:00.418        2.00  5524343.0      0.0100  \n",
       " 2022-04-01 18:21:00.924        2.50  5524500.0      0.1000  \n",
       " 2022-04-01 18:21:01.430        0.01  5524350.0      1.0000  \n",
       " \n",
       " [100 rows x 21 columns],\n",
       " 'trade':                         channel      price  side    size symbol\n",
       " datetime                                                       \n",
       " 2022-04-01 18:13:37.806  trades  5535000.0   BUY  0.0100    BTC\n",
       " 2022-04-01 18:14:18.894  trades  5535000.0   BUY  0.0143    BTC\n",
       " 2022-04-01 18:14:18.894  trades  5535000.0   BUY  0.0002    BTC\n",
       " 2022-04-01 18:14:18.894  trades  5535200.0   BUY  0.0855    BTC\n",
       " 2022-04-01 18:14:23.670  trades  5534999.0  SELL  0.0001    BTC\n",
       " 2022-04-01 18:14:23.670  trades  5533339.0  SELL  0.0010    BTC\n",
       " 2022-04-01 18:14:23.670  trades  5533150.0  SELL  0.0019    BTC\n",
       " 2022-04-01 18:15:13.799  trades  5530400.0   BUY  0.0080    BTC\n",
       " 2022-04-01 18:16:30.679  trades  5530450.0   BUY  0.0100    BTC\n",
       " 2022-04-01 18:17:30.565  trades  5530000.0  SELL  0.0002    BTC\n",
       " 2022-04-01 18:18:24.387  trades  5526000.0  SELL  0.2000    BTC\n",
       " 2022-04-01 18:18:24.604  trades  5526000.0  SELL  0.0500    BTC\n",
       " 2022-04-01 18:18:59.341  trades  5526100.0   BUY  0.0001    BTC\n",
       " 2022-04-01 18:20:29.711  trades  5524215.0   BUY  0.0010    BTC}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import daylib\n",
    "from util import utils\n",
    "dl = daylib.daylib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepro\n",
    "X = self.dg.get_Xy(trades=trades, orderbooks=orderbooks, mode=\"realtime\", method='flatten_v1')\n",
    "X, _ = self.fp.feature_label_split(df=X, target_col=ans_col)\n",
    "X, _ = self.fp.scalingX(X, scaself.ler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(1, 2, 3)\n",
    "        # super().__init__(batch_size=1, drop_last=False)\n",
    "        self.X_tensors = tensors[:-1]\n",
    "        self.y_tensor = tensors[-1]\n",
    "        self.window_size = params[\"window_size\"]\n",
    "        self.batch_size = params[\"batch_size\"]  # keep\n",
    "        self.Xs = [X_tensor.numpy() for X_tensor in self.X_tensors]\n",
    "\n",
    "        if self.y_tensor is None:\n",
    "            # Note; Xs[0] must have data length\n",
    "            length = len(self.Xs[0])\n",
    "            self.y = np.array([np.nan for _ in range(length)])\n",
    "        else:\n",
    "            self.y = self.y_tensor.numpy()\n",
    "\n",
    "        if self.batch_size > len(self.y):\n",
    "            self.batch_size = len(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "        if idx >= (self.window_size - 1):\n",
    "            idx_start = idx - self.window_size + 1\n",
    "            Xs = []\n",
    "            for X in self.Xs:\n",
    "                Xs.append(X[idx_start:idx + 1:])\n",
    "        else:\n",
    "            n_padding = self.window_size - idx - 1\n",
    "            Xs = []\n",
    "            for X in self.Xs:\n",
    "                padding = np.repeat(X[0][None, :], n_padding, axis=0)\n",
    "                X_origin = X[:idx + 1]\n",
    "                X_padded = np.vstack([X_origin, padding])\n",
    "                Xs.append(X_padded)\n",
    "\n",
    "        ys = self.y[idx]\n",
    "        # print(ys)\n",
    "        return Xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/3904501137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSequenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_113/2854399038.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSequenceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# super().__init__(batch_size=1, drop_last=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "\n",
    "SequenceDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self, make, model, year):\n",
    "        self.make = make\n",
    "        self.model = model\n",
    "        self.year = year\n",
    "        self.odometer_readings = 0\n",
    "\n",
    "    def getname(self):\n",
    "        longname = f'{self.year} {self.model} {self.year}'\n",
    "        return longname.title()\n",
    "\n",
    "    def read_odometer(self):\n",
    "        print(f'This car has {self.odometer_readings} miles on it')\n",
    "\n",
    "    def update_odometer(self, mileage):\n",
    "        if mileage >= self.odometer_readings:\n",
    "            self.odometer_readings = mileage\n",
    "        else:\n",
    "            print('You cant roll back  the odometer')\n",
    "\n",
    "    def increment_odometer(self, mileage):\n",
    "        self.odometer_readings += miles\n",
    "\n",
    "class Battery:\n",
    "    def __init__(self, battery_size = 75):\n",
    "        self.battery_size = battery_size\n",
    "\n",
    "    def describe_battery(self):\n",
    "        print(f'This car has a {self.battery_size}-kWh battery in it')\n",
    "\n",
    "    def get_range(self):\n",
    "        if self.battery_size == 75:\n",
    "            range = 260\n",
    "        elif self.battery_size == 1000:\n",
    "            range = 310\n",
    "        print(f\"This car can go {range} miles on a full charge\")\n",
    "\n",
    "class electriccar(Car):\n",
    "    def __init__(self, make, model, year):\n",
    "        super().__init__(make, model, year)\n",
    "        self.battery = Battery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.electriccar at 0x7fe6b2d1ba50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electriccar(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b45f9670391769e061d21fde4a80e23c28183b0e668940abb0d6257953f3010d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
