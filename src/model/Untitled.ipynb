{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87afd94-d7a5-4a6a-9d64-7a2131239e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414fcbc9-453c-4bae-a1ff-8b3eb5619bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgm \n",
    "import numpy  as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6bf66f-5d72-46c1-bfa4-9e3f1de33471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd7f9b6-9820-47d0-86ae-0f1ac6b2bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_master = cgm.CGM(\n",
    "    hidden_dim=15,\n",
    "    vol_input_size=2,\n",
    "    price_input_size=5,\n",
    "    seq_dropout_rate=0.5, \n",
    "    gbl_dropout_rate=0.4,\n",
    "    last_dropout_rate=0.3,\n",
    "    relation_num=3, \n",
    "    output_dim=3, \n",
    "    num_layers=9, \n",
    "    input_dim=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff9f6a1-3165-4090-9182-373adeecd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as ddlta\n",
    "import scipy.stats\n",
    "base_dt =  dt.now().date()\n",
    "ls_datetimes = [ dt.strftime(base_dt + ddlta(minutes=i), format=\"%Y%m%d%H%M\") for i in range(3600)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c26355b-e0d4-4669-ade3-7ac2d55b2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Data\n",
    "company_names = [\"kaisya\",\"Kigyo\",'Otutome','Company'] # 4 Comps \n",
    "time_seqs = range(202204220000,202204220100)\n",
    "# psudo_price ={ company_name: { _time: np.random.rand(5)*100 for _time in time_seqs } for company_name in company_names } # price: ohlcv\n",
    "psudo_price =np.random.rand(len(company_names), len(time_seqs), 5)*100  # simply: Comp * time * features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719e5890-7e27-4c08-bf25-7316f89bb361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Voluem Data\n",
    "company_names = [\"kaisya\",\"Kigyo\",'Otutome','Company']\n",
    "time_seqs = range(202204220000,202204220100)\n",
    "# psudo_price ={ company_name: { _time: np.random.rand(5)*100 for _time in time_seqs } for company_name in company_names } # price: ohlcv\n",
    "psudo_volume =np.random.rand(len(company_names), len(time_seqs), 2)*100  # simply: Comp * time * features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ac9a24-8659-4287-acdd-3c3b9659ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(data,n_feature):\n",
    "    graph = {}\n",
    "    np_graph = []\n",
    "    for _feature_key in range(n_feature):\n",
    "        graph[_feature_key] = {}\n",
    "        layer_1 = []\n",
    "        for _comp_key_1 in range(len(company_names)):\n",
    "            graph[_feature_key][_comp_key_1] = {}\n",
    "            layer_2 = []\n",
    "            for _comp_key_2 in range(len(company_names)):\n",
    "                ir, p = scipy.stats.pearsonr(data[_comp_key_1,:,_feature_key],data[_comp_key_2,:,_feature_key])\n",
    "                graph[_feature_key][_comp_key_1][_comp_key_2] = ir\n",
    "                layer_2.append(ir)\n",
    "            layer_1.append(layer_2)\n",
    "        np_graph.append(layer_1)\n",
    "    return graph,np_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec217e8f-fce8-4dc3-aa5b-575f5db82143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfbdf82-e06e-40e0-bbb8-a2c9c846c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = psudo_price.transpose(1, 0, 2)\n",
    "price_data = torch.from_numpy(price_data).float()\n",
    "\n",
    "volume_data = psudo_volume.transpose(1, 0, 2)\n",
    "volume_data = torch.from_numpy(volume_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b42329-c11f-47f0-9e19-427b83760a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_price = cgm_master.feature_weight_price(price_data[:, :, :5])\n",
    "x_volume = cgm_master.feature_weight_volume(volume_data[:, :, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d412ded-d8a8-43c5-b6c8-54f258ee25fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58669701-e350-4a70-bf64-9a86f9efbf1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "price_graph, price_graph_np = build_graph(x_price.detach().numpy(),5)\n",
    "volume_graph, volume_graph_np = build_graph(x_volume.detach().numpy(),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "640324c1-5b1b-4022-9f86-fa519bee7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_graph_np = torch.from_numpy(np.array(volume_graph_np)).float()\n",
    "price_graph_np = torch.from_numpy(np.array(price_graph_np)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2deb8a3b-9112-470c-92a9-a6cc84a306ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "last_h_time_price = torch.squeeze(x_price[0], 0)  # node feature \n",
    "last_c_time_price = torch.squeeze(x_price[0], 0)  # node feature \n",
    "\n",
    "last_h_time_volume = torch.squeeze(x_volume[0], 0)  # node feature \n",
    "last_c_time_volume = torch.squeeze(x_volume[0], 0)  # node feature \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8817b671-e97a-4ee4-a89f-39ff20033833",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_g_time_price = last_h_time_price\n",
    "last_c_g_time_price = last_c_time_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05b17c14-dc33-4ab4-bbea-18ba28bc907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_g_time_volume = last_h_time_volume\n",
    "last_c_g_time_volume= last_c_time_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd1aa369-b3b8-477a-b59c-8eb8f613e6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "time = len(time_seqs)\n",
    "for t in range(time):\n",
    "    # init\n",
    "    last_h_layer_price = last_h_time_price\n",
    "    last_c_layer_price = last_c_time_price\n",
    "    # information integration \n",
    "    # Each input: Comps * hidden size\n",
    "    last_g_layer_price, last_c_g_layer_price = cgm_master.g_cell.init_forward(last_g_time_price, last_c_g_time_price,last_h_layer_price )\n",
    "    for l in range(cgm_master.num_layers):\n",
    "        # x, h, c, g, h_t, adj\n",
    "        last_h_layer_price, last_c_layer_price = cgm_master.s_cell(\n",
    "                                                                torch.squeeze(x_price[t], 0), \n",
    "                                                                last_h_layer_price,\n",
    "                                                                last_c_layer_price, \n",
    "                                                                last_g_layer_price,\n",
    "                                                                last_h_time_price,\n",
    "                                                                price_graph_np)\n",
    "        # g, c_g, t_g, t_c, h, c\n",
    "        last_g_layer_price, last_c_g_layer_price = cgm_master.g_cell(\n",
    "                                                                last_g_layer_price,\n",
    "                                                                last_c_g_layer_price,\n",
    "                                                                last_g_time_price,\n",
    "                                                                last_c_g_time_price,\n",
    "                                                                last_h_layer_price, \n",
    "                                                                last_c_layer_price)\n",
    "\n",
    "\n",
    "\n",
    "    last_h_time_price, last_c_time_price = last_h_layer_price, last_c_layer_price\n",
    "    last_g_time_price, last_c_g_time_price = last_g_layer_price, last_c_g_layer_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd17d131-5fa6-4fa8-bd5f-39baf9e63d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### volume graph ###\n",
    "\n",
    "time = len(time_seqs)\n",
    "for t in range(time):\n",
    "    # init\n",
    "    last_h_layer_volume = last_h_time_volume\n",
    "    last_c_layer_volume = last_c_time_volume\n",
    "    # information integration \n",
    "    last_g_layer_volume, last_c_g_layer_volume = cgm_master.g_cell.init_forward(\n",
    "                                                                        last_g_time_volume,\n",
    "                                                                        last_c_g_time_volume,\n",
    "                                                                        last_h_layer_volume,\n",
    "                                                                        )\n",
    "    for l in range(cgm_master.num_layers):\n",
    "        # x, h, c, g, h_t, adj\n",
    "        last_h_layer_volume, last_c_layer_volume = cgm_master.s_cell(torch.squeeze(x_volume[t], 0),\n",
    "                                                               last_h_layer_volume, last_c_layer_volume,\n",
    "                                                               last_g_layer_volume, last_h_time_volume, volume_graph_np)\n",
    "        # g, c_g, t_g, t_c, h, c\n",
    "        last_g_layer_volume, last_c_g_layer_volume = cgm_master.g_cell(last_g_layer_volume, last_c_g_layer_volume,\n",
    "                                                                 last_g_time_volume, last_c_g_time_volume,\n",
    "                                                                 last_h_layer_volume, last_c_layer_volume,\n",
    "                                                                 )\n",
    "        \n",
    "    last_h_time_volume, last_c_time_volume = last_h_layer_volume, last_c_layer_volume\n",
    "    last_g_time_volume, last_c_g_time_volume = last_g_layer_volume, last_c_g_layer_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0687c491-c7b3-4f57-9844-485ea2667c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CCA ###\n",
    "cca_price, cca_volume = cgm_master.cca_price(last_h_time_price), cgm_master.cca_volume(last_h_time_volume)\n",
    "last_h_layer, last_c_layer, last_g_layer, last_c_g_layer = last_h_layer_volume, last_c_layer_volume, last_g_layer_volume, last_c_g_layer_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f071351-de9f-4f64-b7d6-925607fd76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_h, cca_price, cca_volume  = last_h_layer, cca_price, cca_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67c443eb-6625-4704-abe5-8cf170ef3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cgm_master.w_out(cgm_master.dropout(last_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "656c1c15-4ef0-4e1d-912c-b5cb397aeb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CGM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50/280210183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'building model...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCGM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CGM' is not defined"
     ]
    }
   ],
   "source": [
    "seed  = 255\n",
    "use_cuda = False\n",
    "restore = False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(255)\n",
    "\n",
    "# checkpoint\n",
    "if restore:  # 存储已有模型的路径\n",
    "    print('loading checkpoint...\\n')\n",
    "    checkpoints = torch.load(os.path.join(log_path, restore))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# model\n",
    "print('building model...\\n')\n",
    "model = CGM(config, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50e33cb3-4a20-4853-b4ea-a1923ac91cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5844,  0.7102, -0.0701],\n",
       "         [-0.1273,  0.1223, -0.4591],\n",
       "         [-0.4914,  0.4389, -0.1866],\n",
       "         [-0.1138,  0.6608, -0.1248]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if args.restore:\n",
    "    model.load_state_dict(checkpoints['model'])\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "if len(args.gpus) > 1:  # 并行\n",
    "    model = nn.DataParallel(model, device_ids=args.gpus, dim=1)\n",
    "logging(repr(model) + \"\\n\\n\")  # 记录这个文件的框架\n",
    "\n",
    "# total number of parameters\n",
    "param_count = 0\n",
    "for param in model.parameters():\n",
    "    param_count += param.view(-1).size()[0]\n",
    "\n",
    "logging('total number of parameters: %d\\n\\n' % param_count)\n",
    "z\n",
    "# updates是已经进行了几个epoch, 防止中间出现程序中断的情况.\n",
    "if args.restore:\n",
    "    updates = checkpoints['updates']\n",
    "    ori_updates = updates\n",
    "else:\n",
    "    updates = 0\n",
    "\n",
    "# optimizer\n",
    "if args.restore:\n",
    "    optim = checkpoints['optim']\n",
    "else:\n",
    "    optim = Optim(config.optim, config.learning_rate, config.max_grad_norm, lr_decay=config.learning_rate_decay,\n",
    "                  start_decay_at=config.start_decay_at)\n",
    "\n",
    "optim.set_parameters(model.parameters())\n",
    "if config.schedule:\n",
    "    scheduler = L.CosineAnnealingLR(optim.optimizer, T_max=config.epoch)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "if not args.notrain:\n",
    "    max_acc, test_acc = train(model, dataloader, scheduler, optim, updates)\n",
    "    logging(\"Best accuracy: %.2f, test accuracy: %.2f\\n\" % (max_acc * 100, test_acc * 100))\n",
    "    return test_acc\n",
    "else:\n",
    "    assert args.restore is not None\n",
    "    eval(model, vocab, dataloader, 0, updates, do_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98345b4c-7d0e-412a-91b9-03749005af23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8008ba-c7f2-41b7-a952-8d8517d10247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a017e877-b57b-4895-8268-3f99a638e2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CGM(\n",
       "  (feature_weight_price): Linear(in_features=7, out_features=5, bias=True)\n",
       "  (feature_weight_volume): Linear(in_features=6, out_features=5, bias=True)\n",
       "  (feature_combine): Linear(in_features=20, out_features=5, bias=True)\n",
       "  (cca_price): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (cca_volume): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (attn_pooling): Attentive_Pooling(\n",
       "    (w_1): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (w_2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (u): Linear(in_features=5, out_features=1, bias=False)\n",
       "  )\n",
       "  (s_cell): SLSTMCell(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (Wh): Linear(in_features=5, out_features=25, bias=False)\n",
       "    (Wn): Linear(in_features=5, out_features=25, bias=False)\n",
       "    (Wt): Linear(in_features=5, out_features=25, bias=False)\n",
       "    (U): Linear(in_features=5, out_features=25, bias=False)\n",
       "    (V): Linear(in_features=5, out_features=25, bias=True)\n",
       "    (rgcn): RGCN(\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (g_cell): GLSTMCell(\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (W): Linear(in_features=5, out_features=10, bias=False)\n",
       "    (w): Linear(in_features=5, out_features=5, bias=False)\n",
       "    (U): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (u): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (attn_pooling): Attentive_Pooling(\n",
       "      (w_1): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (w_2): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (u): Linear(in_features=5, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (w_out): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: node_feature order and contents\n",
    "node_emb = self.node_emb(span_nodes)  # idx of node\n",
    "\n",
    "x_volume = self.feature_weight_volume(node_feature[:, :, 6:])\n",
    "\n",
    "### price graph ###\n",
    "last_h_time_price = torch.squeeze(x_price[0], 0)  # node feature \n",
    "last_c_time_price = torch.squeeze(x_price[0], 0)  # node feature \n",
    "\n",
    "last_g_time_price = self.attn_pooling(last_h_time_price, node_emb)\n",
    "last_c_g_time_price = self.attn_pooling(last_c_time_price, node_emb)\n",
    "# h_states = []\n",
    "\n",
    "time = node_feature.size(0)\n",
    "for t in range(time):\n",
    "    # init\n",
    "    last_h_layer_price = last_h_time_price\n",
    "    last_c_layer_price = last_c_time_price\n",
    "    # information integration \n",
    "    last_g_layer_price, last_c_g_layer_price = self.g_cell.init_forward(last_g_time_price, last_c_g_time_price,\n",
    "                                                                        last_h_layer_price, last_c_layer_price,\n",
    "                                                                        node_emb)\n",
    "    for l in range(self.num_layers):\n",
    "        # x, h, c, g, h_t, adj\n",
    "        last_h_layer_price, last_c_layer_price = self.s_cell(torch.squeeze(x_price[t], 0), last_h_layer_price,\n",
    "                                                             last_c_layer_price, last_g_layer_price,\n",
    "                                                             last_h_time_price, adj)\n",
    "        # g, c_g, t_g, t_c, h, c\n",
    "        last_g_layer_price, last_c_g_layer_price = self.g_cell(last_g_layer_price, last_c_g_layer_price,\n",
    "                                                               last_g_time_price, last_c_g_time_price,\n",
    "                                                               last_h_layer_price, last_c_layer_price, node_emb)\n",
    "\n",
    "\n",
    "    last_h_time_price, last_c_time_price = last_h_layer_price, last_c_layer_price\n",
    "    last_g_time_price, last_c_g_time_price = last_g_layer_price, last_c_g_layer_price\n",
    "\n",
    "### volume graph ###\n",
    "last_h_time_volume = torch.squeeze(x_volume[0], 0)  # node feature \n",
    "last_c_time_volume = torch.squeeze(x_volume[0], 0)  # node feature \n",
    "last_g_time_volume = self.attn_pooling(last_h_time_volume, node_emb)\n",
    "last_c_g_time_volume = self.attn_pooling(last_c_time_volume, node_emb)\n",
    "# h_states = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f988a8-387a-4066-b009-e9de2551a832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
